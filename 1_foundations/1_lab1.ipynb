{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "# from openai import OpenAI\n",
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "# openai = OpenAI()\n",
    "\n",
    "anthropic = Anthropic(api_key=anthropic_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2+2 = 4\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "# response = openai.chat.completions.create(\n",
    "#     model=\"gpt-4.1-nano\",\n",
    "#     messages=messages\n",
    "# )\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "response = anthropic.messages.create(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    max_tokens=1024,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.content[0].text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If a clock takes 6 seconds to strike 4 o'clock (with evenly-spaced strikes beginning at the first strike), how many seconds will it take to strike 8 o'clock?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "# response = openai.chat.completions.create(\n",
    "#     model=\"gpt-4.1-mini\",\n",
    "#     messages=messages\n",
    "# )\n",
    "\n",
    "# question = response.choices[0].message.content\n",
    "\n",
    "response = anthropic.messages.create(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    max_tokens=1024,\n",
    "    messages=messages\n",
    ")\n",
    "question = response.content[0].text\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask it again\n",
    "\n",
    "# response = openai.chat.completions.create(\n",
    "#     model=\"gpt-4.1-mini\",\n",
    "#     messages=messages\n",
    "# )\n",
    "# answer = response.choices[0].message.content\n",
    "response = anthropic.messages.create(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    max_tokens=1024,\n",
    "    messages=messages\n",
    ")\n",
    "answer = response.content[0].text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I need to figure out the timing pattern of the clock strikes.\n",
       "\n",
       "When the clock strikes 4 o'clock:\n",
       "- There are 4 strikes total\n",
       "- The strikes occur at specific moments in time\n",
       "- It takes 6 seconds total from the first strike to the last strike\n",
       "\n",
       "The key insight is that between 4 strikes, there are only 3 intervals (gaps between strikes).\n",
       "\n",
       "Let me visualize this:\n",
       "- Strike 1 (at 0 seconds)\n",
       "- Strike 2 (at time t)\n",
       "- Strike 3 (at time 2t)\n",
       "- Strike 4 (at time 3t)\n",
       "\n",
       "So 3 intervals take 6 seconds, meaning each interval is 6 ÷ 3 = 2 seconds.\n",
       "\n",
       "For 8 o'clock:\n",
       "- There are 8 strikes\n",
       "- This creates 7 intervals between strikes\n",
       "- Each interval is still 2 seconds\n",
       "\n",
       "Total time = 7 intervals × 2 seconds per interval = 14 seconds\n",
       "\n",
       "Therefore, it will take **14 seconds** to strike 8 o'clock."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the messages:\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"pick a business area in automation of production lines for agentic ai opportunities\"}]\n",
    "\n",
    "response = anthropic.messages.create(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    max_tokens=1024,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response.content[0].text\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(business_idea)\n",
    "messages = [{\"role\": \"user\", \"content\": f\"present a pain-point in that industry: {business_idea}\"}]\n",
    "\n",
    "response = anthropic.messages.create(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    max_tokens=1024,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "pain_point = response.content[0].text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Pain Point Analysis: Quality Control & Defect Detection in Manufacturing\n",
       "\n",
       "## 🔴 The Core Problem\n",
       "\n",
       "### **\"The Whack-a-Mole Quality Crisis\"**\n",
       "\n",
       "Manufacturing quality teams are trapped in a reactive cycle where fixing one defect source reveals three more, while the real root causes remain hidden in data silos.\n",
       "\n",
       "---\n",
       "\n",
       "## Critical Pain Points\n",
       "\n",
       "### 1. **The False Positive Nightmare** 💸\n",
       "**Reality:** Traditional vision systems flag 20-40% false positives\n",
       "- Line operators waste 2-3 hours/shift investigating \"defects\" that aren't real\n",
       "- **Cost:** $150K-500K/year per line in wasted labor\n",
       "- Builds \"alarm fatigue\" - operators start ignoring alerts\n",
       "- Real defects slip through when trust erodes\n",
       "\n",
       "*\"We have three engineers who basically babysit the camera system all day. Their job is to tell the AI it's wrong.\"* - QC Manager, automotive tier-1 supplier\n",
       "\n",
       "---\n",
       "\n",
       "### 2. **Root Cause Hide-and-Seek** 🕵️\n",
       "**The Problem:** Defects detected at Station 10 were caused at Station 3, two hours ago\n",
       "\n",
       "- Current systems take 4-6 hours to trace defect origins\n",
       "- By then, 2,000+ units potentially affected\n",
       "- Engineers manually correlate across 15+ disconnected data sources\n",
       "- 60% of investigations end with \"unknown cause\"\n",
       "\n",
       "**Real cost example:**\n",
       "- Defect discovered: 2:00 PM\n",
       "- Root cause identified: 8:00 PM (next shift)\n",
       "- Contaminated production: 6 hours × 350 units/hr = 2,100 units\n",
       "- Quarantine & reinspection cost: $180K\n",
       "\n",
       "---\n",
       "\n",
       "### 3. **The Threshold Tuning Treadmill** ⚖️\n",
       "**The Dilemma:** Too strict = scrap good products. Too loose = ship defects.\n",
       "\n",
       "Current state:\n",
       "- Engineers manually adjust thresholds quarterly (or after major customer complaints)\n",
       "- No feedback loop from field failures to inspection parameters\n",
       "- Settings optimized for \"average\" conditions, fail during edge cases\n",
       "- Each product variant needs separate manual tuning (weeks of work)\n",
       "\n",
       "**Impact:**\n",
       "- 5-15% of scrapped product was actually good (over-rejection)\n",
       "- 0.5-2% defect escape rate to customers (under-rejection)\n",
       "- Warranty claims 3x higher than theoretical minimum\n",
       "\n",
       "---\n",
       "\n",
       "### 4. **The Invisible Degradation** 📉\n",
       "**Silent Killer:** Production quality slowly drifts, unnoticed until catastrophic\n",
       "\n",
       "- Tool wear, calibration drift, supplier lot variations accumulate\n",
       "- No system tracking \"almost defects\" that predict future problems\n",
       "- Quality appears fine until sudden spike in failures\n",
       "\n",
       "*Classic pattern:*\n",
       "- Week 1-8: Everything looks normal\n",
       "- Week 9: Sudden 400% increase in defects\n",
       "- Forensics reveal process degraded gradually for weeks\n",
       "- Could have been prevented if early signals were caught\n",
       "\n",
       "---\n",
       "\n",
       "## Why Current Solutions Fail\n",
       "\n",
       "| Approach | Why It's Inadequate |\n",
       "|----------|---------------------|\n",
       "| **Manual inspection** | Inconsistent (70-80% accuracy), expensive, can't scale to 100% inspection |\n",
       "| **Traditional machine vision** | Brittle, high false positives, requires extensive programming per SKU |\n",
       "| **Basic ML models** | Static thresholds, can't explain decisions, no contextual awareness |\n",
       "| **Isolated IoT sensors** | Data exists but no intelligence connecting the dots |\n",
       "\n",
       "---\n",
       "\n",
       "## The Financial Stakes\n",
       "\n",
       "### For a mid-sized manufacturer ($500M revenue):\n",
       "\n",
       "**Annual quality-related costs:**\n",
       "- Internal scrap/rework: $8-15M\n",
       "- Warranty claims: $5-12M  \n",
       "- Recall risk exposure: $20-100M\n",
       "- Customer penalties/lost business: $3-8M\n",
       "\n",
       "**Total addressable pain: $36-135M/year**\n",
       "\n",
       "**Current QC spending:** $4-8M/year\n",
       "- Yet problems persist because tools are reactive, not intelligent\n",
       "\n",
       "---\n",
       "\n",
       "## What Makes This Perfect for Agentic AI?\n",
       "\n",
       "### ✅ **Decision Density**\n",
       "Hundreds of micro-decisions per minute that humans can't handle:\n",
       "- Is this mark a defect or cosmetic variation?\n",
       "- Should I trigger deep inspection on next unit?\n",
       "- Which upstream parameter changed?\n",
       "\n",
       "### ✅ **Multi-Agent Natural Fit**\n",
       "Different agents need different"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(pain_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
